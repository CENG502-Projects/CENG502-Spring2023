{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fd4ce-0aa1-450c-a885-4562d7bb5f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, hashlib, torch\n",
    "from nltk import ngrams, word_tokenize\n",
    "\n",
    "#nltk.download(\"punkt\")\n",
    "unigramCount = 200000\n",
    "bigramCount = 1000000\n",
    "trigramCount = 64000\n",
    "def create_string_embeddings(text):\n",
    "    bow = []\n",
    "\n",
    "    for s in text:\n",
    "        # word unigram 200.000\n",
    "        print(\"first text is::::::\", s)\n",
    "        uni = list(ngrams( word_tokenize(s), 1 ) )\n",
    "        unigrams = [\"\".join(i) for i in uni ]\n",
    "        unigramN = [int(hashlib.sha1(p.encode('utf-8')).hexdigest(), 16) % (unigramCount-1) + 1 for p in unigrams]\n",
    "        #print(\"======word unigrams:\", unigrams, unigramN)\n",
    "\n",
    "        # word bigrams 1.000.000\n",
    "        bis = list( ngrams( word_tokenize(s), 2) )\n",
    "        bigrams = [\"\".join( i[0]+\" \"+i[1] ) for i in bis]\n",
    "        bigramN = [int(hashlib.sha1(p.encode('utf-8')).hexdigest(), 16) % (bigramCount-1) + unigramCount + 1 for p in bigrams]\n",
    "        #print(\"word bigrams:\", bigrams, bigramN )\n",
    "\n",
    "        #character trigrams 64.000\n",
    "        tris = list(ngrams(s,3))\n",
    "        trigrams = [\"\".join(i) for i in tris]\n",
    "        trigramN = [int(hashlib.sha1(p.encode('utf-8')).hexdigest(), 16) % (trigramCount-1) + bigramCount + unigramCount + 1 for p in trigrams]\n",
    "\n",
    "        #print(\"character trigrams:\", trigrams, trigramN )\n",
    "        cur = unigramN + bigramN + trigramN\n",
    "        bow.append( cur + [0]*(100-len(cur)))\n",
    "        #print(\"bow is:\", bow)\n",
    "    \n",
    "    return bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9124c9-957b-4bcc-9cac-e38e48bfe657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import mmh3\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, emsize, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.ntokens = ntoken\n",
    "        \n",
    "        self.E = nn.Embedding(ntoken,256,padding_idx=0)\n",
    "        self.W = nn.Embedding(unigramCount+bigramCount+trigramCount, 2)\n",
    "        self.clsToken = torch.randn((1,512))\n",
    "        \n",
    "        self.textLinear = nn.Linear(100*256,512)\n",
    "        self.imageLinear = nn.Linear(2048,512)\n",
    "        self.clsLinear = nn.Linear(512,512)\n",
    "        \n",
    "        encoder_layers = TransformerEncoderLayer(emsize, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(1024, 256))\n",
    "\n",
    "        #self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, txtsrc, imgsrc):        \n",
    "        out = create_string_embeddings(txtsrc)\n",
    "        out = torch.Tensor(out)\n",
    "        \n",
    "        # Get 2 different hash index from W for each token ID & Get 2 importance weight from E for each token ID\n",
    "        txtEmbeddings = torch.Tensor()\n",
    "        for ems in out: \n",
    "            stringEmbedding = torch.Tensor([])\n",
    "            for hvalue in ems:\n",
    "                if hvalue != 0:\n",
    "                    hash1index = mmh3.hash(str(hvalue), seed=1) % self.ntokens\n",
    "                    hash2index = mmh3.hash(str(hvalue), seed=2) % self.ntokens\n",
    "                    hashes = self.E( torch.IntTensor([hash1index, hash2index]) )\n",
    "                    \n",
    "                    importanceWeights = self.W( hvalue.int() )\n",
    "                    #print(\"here is the hashes:\", hashes, \" importance weights: \", importanceWeights)\n",
    "                    #print(\"final embeddings are:\", (hashes[0]*importanceWeights[0] + hashes[1]*importanceWeights[1])/2 )\n",
    "                    finalEmbedding = (hashes[0]*importanceWeights[0] + hashes[1]*importanceWeights[1])/2\n",
    "                    stringEmbedding = torch.cat([stringEmbedding, finalEmbedding])\n",
    "                    #print(\"string Embedding is: \", stringEmbedding.shape )\n",
    "                else:\n",
    "                    stringEmbedding = torch.cat([stringEmbedding, torch.zeros([256])])\n",
    "            #print(\"Last string Embedding is: \", stringEmbedding.unsqueeze(0).shape )\n",
    "            txtEmbeddings = torch.cat([txtEmbeddings, stringEmbedding.unsqueeze(0)])\n",
    "        \n",
    "        \n",
    "        # pass the hashes to textLinear\n",
    "        txtEmbeddings = self.textLinear(txtEmbeddings)\n",
    "        \n",
    "        # pass the image embeddings to imgLinear\n",
    "        imgEmbeddings = self.imageLinear(imgsrc)\n",
    "        \n",
    "        # get cls token\n",
    "        clsToken = self.clsLinear(self.clsToken)\n",
    "        \n",
    "        allEmbeddings = torch.cat([clsToken, txtEmbeddings, imgEmbeddings])\n",
    "        print(\"All Embedding shape: \", allEmbeddings.shape)\n",
    "        \n",
    "        output = self.transformer_encoder(allEmbeddings)\n",
    "        print(output[0].shape)\n",
    "        output = self.seq( output[0] )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1bfad-aec5-4144-ac01-18cd60e74b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import ResNetModel, AutoProcessor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ntokens = 100000 # the size of vocabulary\n",
    "emsize = 512 # embedding dimension\n",
    "nhid = 512 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 1 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 8 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout)\n",
    "\n",
    "# GET INPUT\n",
    "\n",
    "# Create embeddings for strings\n",
    "txtsrc = [\"ali gel\"]\n",
    "txtsrc.append(\"hello world how are you\")\n",
    "txtsrc.append(\"asl aldanan aldansin salla azini yolla\")\n",
    "\n",
    "\n",
    "# Get embeddings for images\n",
    "model_name = \"microsoft/resnet-50\"\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "resnetModel = ResNetModel.from_pretrained(model_name)\n",
    "images = [\"horses.jpg\", \"horses.jpg\", \"horses.jpg\", \"horses.jpg\", \"horses.jpg\"]\n",
    "\n",
    "imgEmbeddings = torch.Tensor()\n",
    "for img in images:\n",
    "    imread = plt.imread(img)\n",
    "    processedImage = processor(imread,return_tensors=\"pt\")[\"pixel_values\"]\n",
    "    sonuc = resnetModel(processedImage)\n",
    "    imgEmbeddings = torch.cat( [imgEmbeddings, sonuc.pooler_output.squeeze(-1).squeeze(-1)] )\n",
    "\n",
    "print(imgEmbeddings)\n",
    "\n",
    "model(txtsrc, imgEmbeddings).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36246ab2-de5f-42c7-9563-3ce30ece80cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.cat((p, torch.Tensor([1,2,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534b1c0-3914-4e10-9ed2-d95461f8a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((p, torch.Tensor([2,4,5]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899cb80c-b68b-4bfa-a9dd-c17c801fb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = torch.tensor([])\n",
    "x = torch.unsqueeze( torch.randn( 7), dim=0 )\n",
    "y = torch.cat([empty, x])\n",
    "y = torch.cat([y, x]).unsqueeze(0)\n",
    "print(y )\n",
    "\n",
    "empty2 = torch.Tensor()\n",
    "z = torch.cat([empty2, y])\n",
    "z = torch.cat([z, y])\n",
    "print(\"z is:\",z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b384b7f7-1fbb-4561-9c6d-e9e9eeb7c466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
